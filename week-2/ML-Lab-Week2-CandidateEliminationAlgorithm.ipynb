{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country Manufacturer  Color  Year     Type Likeable\n",
      "0  Japan         Honda  Blue   1980  Economy      Yes\n",
      "1  Japan        Toyota  Green  1970   Sports       No\n",
      "2  Japan        Toyota  Blue   1990  Economy      Yes\n",
      "3     USA     Chrysler    Red  1980  Economy       No\n",
      "4  Japan         Honda  White  1980  Economy      Yes \n",
      "\n",
      "\n",
      "X = \n",
      " [['Japan ' 'Honda' 'Blue ' 1980 'Economy']\n",
      " ['Japan ' 'Toyota' 'Green' 1970 'Sports']\n",
      " ['Japan ' 'Toyota' 'Blue ' 1990 'Economy']\n",
      " ['USA' 'Chrysler' 'Red' 1980 'Economy']\n",
      " ['Japan ' 'Honda' 'White' 1980 'Economy']]\n",
      "\n",
      "Y = \n",
      " ['Yes' 'No' 'Yes' 'No' 'Yes']\n",
      "\n",
      "\n",
      "\n",
      "  Country Manufacturer  Color  Year     Type Likeable\n",
      "0  Japan         Honda  Blue   1980  Economy      Yes\n",
      "1  Japan        Toyota  Green  1970   Sports       No\n",
      "2  Japan        Toyota  Blue   1990  Economy      Yes\n",
      "3     USA     Chrysler    Red  1980  Economy       No\n",
      "4  Japan         Honda  White  1980  Economy      Yes\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, target):\n",
    "    dataset = pd.read_csv(filename, sep=\",\")  # read .csv file into dataset variable\n",
    "\n",
    "    print(dataset,\"\\n\")\n",
    "\n",
    "    x = np.array(dataset.drop([target],1)) # x contains all the features. Does not include target\n",
    "    y = np.array(dataset[target]) # y contains the target class \n",
    "\n",
    "    print(\"\\nX = \\n\",x)\n",
    "    print(\"\\nY = \\n\",y)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    return (dataset,x,y,target)\n",
    "\n",
    "inp = load_data(\"EconomyCar.csv\",\"Likeable\")\n",
    "print(inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header Names:  ('Country', 'Manufacturer', 'Color', 'Year', 'Type')\n",
      "\n",
      "Dataset:  [(('Japan ', 'Honda', 'Blue ', 1980, 'Economy'), 'Yes'), (('Japan ', 'Toyota', 'Green', 1970, 'Sports'), 'No'), (('Japan ', 'Toyota', 'Blue ', 1990, 'Economy'), 'Yes'), (('USA', 'Chrysler', 'Red', 1980, 'Economy'), 'No'), (('Japan ', 'Honda', 'White', 1980, 'Economy'), 'Yes')]\n"
     ]
    }
   ],
   "source": [
    "def convert_data(dataset,x,y,target):\n",
    "    header_names = []\n",
    "    for i in range(len(dataset.columns)):\n",
    "        if dataset.columns[i] != target:\n",
    "            header_names.append(dataset.columns[i])\n",
    "    print(\"Header Names: \",tuple(header_names))\n",
    "    \n",
    "    #print(\"srihari\",len(dataset))\n",
    "    data = []\n",
    "    for i in range(len(dataset)):\n",
    "        new = [(tuple(x[i])),y[i]]\n",
    "        data.append(tuple(new))\n",
    "    \n",
    "    print(\"\\nDataset: \",data)\n",
    "    \n",
    "    return (data, header_names)\n",
    "    \n",
    "    \n",
    "data_inp = convert_data(inp[0],inp[1],inp[2],inp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Factors:  {'Country': ['Japan ', 'USA'], 'Manufacturer': ['Honda', 'Toyota', 'Chrysler'], 'Color': ['Blue ', 'Green', 'Red', 'White'], 'Year': [1980, 1970, 1990], 'Type': ['Economy', 'Sports']}\n",
      "\n",
      "Attributes:  ['Country', 'Manufacturer', 'Color', 'Year', 'Type']\n"
     ]
    }
   ],
   "source": [
    "class holder():\n",
    "    factors = {}\n",
    "    attributes = ()\n",
    "    \n",
    "    def __init__(self,attr):\n",
    "        self.attributes = attr\n",
    "        for i in attr:\n",
    "            self.factors[i] = []\n",
    "            \n",
    "    def add_values(self,data,header_names):\n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(header_names)):\n",
    "                # 3dimensions as 2 tuples in data\n",
    "                if data[i][0][j] not in self.factors[header_names[j]]:\n",
    "                    self.factors[header_names[j]].append(data[i][0][j])\n",
    "\n",
    "f = holder(data_inp[1])\n",
    "f.add_values(data_inp[0],data_inp[1])\n",
    "print(\"\\nFactors: \",f.factors)\n",
    "print(\"\\nAttributes: \",f.attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input 1:  (('Japan ', 'Honda', 'Blue ', 1980, 'Economy'), 'Yes')\n",
      "Positive\n",
      "S1:  [('Japan ', 'Honda', 'Blue ', 1980, 'Economy')]\n",
      "G1:  [('?', '?', '?', '?', '?')]\n",
      "\n",
      "Input 2:  (('Japan ', 'Toyota', 'Green', 1970, 'Sports'), 'No')\n",
      "Negative\n",
      "S2:  [('Japan ', 'Honda', 'Blue ', 1980, 'Economy')]\n",
      "G2:  [('?', 'Honda', '?', '?', '?'), ('?', '?', 'Blue ', '?', '?'), ('?', '?', '?', 1980, '?'), ('?', '?', '?', '?', 'Economy')]\n",
      "\n",
      "Input 3:  (('Japan ', 'Toyota', 'Blue ', 1990, 'Economy'), 'Yes')\n",
      "Positive\n",
      "S3:  [('Japan ', '?', 'Blue ', '?', 'Economy')]\n",
      "G3:  [('?', '?', 'Blue ', '?', '?'), ('?', '?', '?', '?', 'Economy')]\n",
      "\n",
      "Input 4:  (('USA', 'Chrysler', 'Red', 1980, 'Economy'), 'No')\n",
      "Negative\n",
      "S4:  [('Japan ', '?', 'Blue ', '?', 'Economy')]\n",
      "G4:  [('?', '?', 'Blue ', '?', '?'), ('Japan ', '?', '?', '?', 'Economy')]\n",
      "\n",
      "Input 5:  (('Japan ', 'Honda', 'White', 1980, 'Economy'), 'Yes')\n",
      "Positive\n",
      "S5:  [('Japan ', '?', '?', '?', 'Economy')]\n",
      "G5:  [('Japan ', '?', '?', '?', 'Economy')]\n",
      "\n",
      "Final S:  [('Japan ', '?', '?', '?', 'Economy')]\n",
      "Final G:  [('Japan ', '?', '?', '?', 'Economy')]\n"
     ]
    }
   ],
   "source": [
    "class CandidateElimination():\n",
    "    Positive = {}\n",
    "    Negative = {}\n",
    "    \n",
    "    def __init__(self,data,fact):\n",
    "        self.num_factors = len(data[0][0])\n",
    "        self.factors = fact.factors\n",
    "        self.attr = fact.attributes\n",
    "        self.dataset = data\n",
    "        \n",
    "\n",
    "    def run_algorithm(self):\n",
    "        G = self.initializeG()\n",
    "        #print(type(G[0]))\n",
    "        S = self.initializeS()\n",
    "        \n",
    "        count = 0\n",
    "        for trial_set in self.dataset:  # check for every input\n",
    "            count+=1\n",
    "            print(\"\\nInput %d: \"%(count),trial_set)\n",
    "            if self.is_positive(trial_set):  \n",
    "                print(\"Positive\")\n",
    "                #print(trial_set[0])\n",
    "                G = self.remove_inconsistent_G(G,trial_set[0])\n",
    "                S_new = S[:]\n",
    "                #print(\"S_new: \",S_new)\n",
    "                for s in S:\n",
    "                    \n",
    "                    if not self.consistent(s,trial_set[0]):\n",
    "                        S_new.remove(s)\n",
    "                        #print(trial_set[0])\n",
    "                        generalization = self.generalize_inconsistent_S(s, trial_set[0])\n",
    "                        generalization = self.get_general(generalization,G)\n",
    "                        \n",
    "                        if generalization: \n",
    "                            S_new.append(generalization)\n",
    "                    S = S_new[:]\n",
    "                    S = self.remove_more_general(S)\n",
    "                print(\"S%d: \"%(count),S)\n",
    "                print(\"G%d: \"%(count),G)\n",
    "                    \n",
    "                    \n",
    "            else:   # if negative input\n",
    "                print(\"Negative\")\n",
    "                S = self.remove_inconsistent_S(S, trial_set[0])\n",
    "                G_new = G[:]\n",
    "                for g in G:\n",
    "                    if self.consistent(g,trial_set[0]):\n",
    "                        G_new.remove(g)\n",
    "                        specialization = self.specialize_inconsistent_G(g, trial_set[0])\n",
    "                        #print(\"srihari\",specialization)\n",
    "                        specialization = self.get_specific(specialization, S)\n",
    "                        if specialization != []:\n",
    "                            G_new += specialization\n",
    "                    G = G_new[:]\n",
    "                    G = self.remove_more_specific(G)\n",
    "                print(\"S%d: \"%(count),S)\n",
    "                print(\"G%d: \"%(count),G)\n",
    "\n",
    "        print(\"\\nFinal S: \", S)\n",
    "        print(\"Final G: \",G)\n",
    "                \n",
    "        \n",
    "    def initializeG(self):\n",
    "        G = tuple(['?' for i in range(self.num_factors)])\n",
    "        return [G]\n",
    "    \n",
    "    def initializeS(self):\n",
    "        S = tuple(['-' for i in range(self.num_factors)])\n",
    "        return [S]\n",
    "    \n",
    "    def is_positive(self,trial_set):\n",
    "        if trial_set[1] == 'Yes' or trial_set[1] == 1:\n",
    "            return True\n",
    "        elif trial_set[1] == 'No' or trial_set[1] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            raise TypeError(\"Invalid Target Value\")\n",
    "            \n",
    "    def remove_inconsistent_G(self,hypothesis,instance):\n",
    "        G_new = hypothesis[:]\n",
    "        for g in hypothesis:\n",
    "            if not self.consistent(g,instance):\n",
    "                G_new.remove(g)              \n",
    "        return G_new\n",
    "    \n",
    "    def remove_inconsistent_S(self,hypothesis,instance):\n",
    "        S_new = hypothesis[:]\n",
    "        for s in hypothesis:\n",
    "            if self.consistent(s,instance):\n",
    "                S_new.remove(s)  \n",
    "        return S_new\n",
    "    \n",
    "    \n",
    "    def consistent(self, hypothesis, instance):\n",
    "        for i,factor in enumerate(hypothesis):\n",
    "            # enumerate returns index,val\n",
    "            if not self.match_factor(factor, instance[i]):\n",
    "                return False\n",
    "        return True\n",
    "            \n",
    "    def match_factor(self, val1, val2):\n",
    "        if val1 == '?' or val2 == '?':\n",
    "            return True\n",
    "        elif val1 == val2:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def generalize_inconsistent_S(self, hypothesis,instance):\n",
    "        hypo = list(hypothesis)\n",
    "        for i,factor in enumerate(hypo):\n",
    "            if factor == '-':\n",
    "                hypo[i] = instance[i]\n",
    "            elif not self.match_factor(factor,instance[i]):\n",
    "                hypo[i] = '?'\n",
    "        return tuple(hypo)\n",
    "    \n",
    "    def specialize_inconsistent_G(self, hypothesis,instance):\n",
    "        specializations = []\n",
    "        hypo = list(hypothesis)\n",
    "        for i,factor in enumerate(hypo):\n",
    "            if factor == '?':\n",
    "                values = self.factors[self.attr[i]]\n",
    "                for j in values:\n",
    "                    if instance[i] != j:\n",
    "                        hyp = hypo[:]\n",
    "                        hyp[i] = j\n",
    "                        hyp=tuple(hyp)                        \n",
    "                        specializations.append(hyp)\n",
    "        return specializations\n",
    "    \n",
    "    def get_general(self, generalization, G):\n",
    "        for g in G:\n",
    "            if self.more_general(g,generalization):\n",
    "                return generalization\n",
    "        return None\n",
    "    \n",
    "    def get_specific(self, specializations, S):\n",
    "        valid_specialization = []\n",
    "        for hypo in specializations:\n",
    "            for s in S:\n",
    "                if self.more_specific(s,hypo) or s==self.initializeS()[0]:\n",
    "                    valid_specialization.append(hypo)\n",
    "        return valid_specialization\n",
    "    \n",
    "    def more_general(self, hypo1, hypo2):\n",
    "        hyp = zip(hypo1,hypo2)\n",
    "        for i,j in hyp:\n",
    "            if i == '?':\n",
    "                continue\n",
    "            elif j == '?' and i != '?':\n",
    "                return False\n",
    "            elif i != j:\n",
    "                return False\n",
    "            else:\n",
    "                continue\n",
    "        return True\n",
    "    \n",
    "    def more_specific(self,hypo1,hypo2):\n",
    "        return self.more_general(hypo2, hypo1)\n",
    "        \n",
    "    def remove_more_general(self, hypotheses):\n",
    "        S_new = hypotheses[:]\n",
    "        for old in hypotheses:\n",
    "            for new in S_new:\n",
    "                if old != new and self.more_general(new,old):\n",
    "                    S_new.remove[new]\n",
    "                    \n",
    "        return S_new\n",
    "    \n",
    "    def remove_more_specific(self, hypotheses):\n",
    "        G_new = hypotheses[:]\n",
    "        for old in hypotheses:\n",
    "            for new in G_new:\n",
    "                if old != new and self.more_specific(new,old):\n",
    "                    G_new.remove(new)\n",
    "                    \n",
    "        return G_new\n",
    "            \n",
    "#print(f)\n",
    "output = CandidateElimination(data_inp[0],f)\n",
    "output.run_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
