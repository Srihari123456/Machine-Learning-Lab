{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing of modules\n",
    "\n",
    "import numpy as np     # for math functions\n",
    "import pandas as pd    # for importing and using datasets\n",
    "import random          # for generating random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temperature  nausea  lumbarpain  urinepushing  pains  burning  \\\n",
      "0          35,5       0           1             0      0        0   \n",
      "1          35,9       0           0             1      1        1   \n",
      "2          35,9       0           1             0      0        0   \n",
      "3          36,0       0           0             1      1        1   \n",
      "4          36,0       0           1             0      0        0   \n",
      "..          ...     ...         ...           ...    ...      ...   \n",
      "115        41,4       0           1             1      0        1   \n",
      "116        41,5       0           0             0      0        0   \n",
      "117        41,5       1           1             0      1        0   \n",
      "118        41,5       0           1             1      0        1   \n",
      "119        41,5       0           1             1      0        1   \n",
      "\n",
      "     inflamation  decision  \n",
      "0              0         0  \n",
      "1              1         0  \n",
      "2              0         0  \n",
      "3              1         0  \n",
      "4              0         0  \n",
      "..           ...       ...  \n",
      "115            0         1  \n",
      "116            0         0  \n",
      "117            0         1  \n",
      "118            0         1  \n",
      "119            0         1  \n",
      "\n",
      "[120 rows x 8 columns] \n",
      "\n",
      "\n",
      "X = \n",
      " [['35,5' 0 1 0 0 0 0]\n",
      " ['35,9' 0 0 1 1 1 1]\n",
      " ['35,9' 0 1 0 0 0 0]\n",
      " ['36,0' 0 0 1 1 1 1]\n",
      " ['36,0' 0 1 0 0 0 0]\n",
      " ['36,0' 0 1 0 0 0 0]\n",
      " ['36,2' 0 0 1 1 1 1]\n",
      " ['36,2' 0 1 0 0 0 0]\n",
      " ['36,3' 0 0 1 1 1 1]\n",
      " ['36,6' 0 0 1 1 1 1]\n",
      " ['36,6' 0 0 1 1 1 1]\n",
      " ['36,6' 0 1 0 0 0 0]\n",
      " ['36,6' 0 1 0 0 0 0]\n",
      " ['36,7' 0 0 1 1 1 1]\n",
      " ['36,7' 0 1 0 0 0 0]\n",
      " ['36,7' 0 1 0 0 0 0]\n",
      " ['36,8' 0 0 1 1 1 1]\n",
      " ['36,8' 0 0 1 1 1 1]\n",
      " ['36,9' 0 0 1 1 1 1]\n",
      " ['36,9' 0 1 0 0 0 0]\n",
      " ['37,0' 0 0 1 1 0 1]\n",
      " ['37,0' 0 0 1 1 0 1]\n",
      " ['37,0' 0 1 0 0 0 0]\n",
      " ['37,0' 0 0 1 1 1 1]\n",
      " ['37,0' 0 0 1 1 1 1]\n",
      " ['37,0' 0 0 1 1 1 1]\n",
      " ['37,0' 0 0 1 1 1 1]\n",
      " ['37,0' 0 0 1 0 0 1]\n",
      " ['37,1' 0 1 0 0 0 0]\n",
      " ['37,1' 0 0 1 1 1 1]\n",
      " ['37,1' 0 0 1 0 0 1]\n",
      " ['37,2' 0 0 1 1 0 1]\n",
      " ['37,2' 0 1 0 0 0 0]\n",
      " ['37,2' 0 0 1 0 0 1]\n",
      " ['37,3' 0 1 0 0 0 0]\n",
      " ['37,3' 0 0 1 1 1 1]\n",
      " ['37,3' 0 0 1 0 0 1]\n",
      " ['37,4' 0 1 0 0 0 0]\n",
      " ['37,4' 0 0 1 0 0 1]\n",
      " ['37,5' 0 0 1 1 0 1]\n",
      " ['37,5' 0 1 0 0 0 0]\n",
      " ['37,5' 0 1 0 0 0 0]\n",
      " ['37,5' 0 0 1 1 1 1]\n",
      " ['37,5' 0 0 1 0 0 1]\n",
      " ['37,5' 0 0 1 0 0 1]\n",
      " ['37,6' 0 0 1 1 0 1]\n",
      " ['37,6' 0 0 1 1 0 1]\n",
      " ['37,6' 0 0 1 1 1 1]\n",
      " ['37,7' 0 0 1 1 0 1]\n",
      " ['37,7' 0 0 1 1 0 1]\n",
      " ['37,7' 0 1 0 0 0 0]\n",
      " ['37,7' 0 0 1 0 0 1]\n",
      " ['37,8' 0 1 0 0 0 0]\n",
      " ['37,8' 0 0 1 1 1 1]\n",
      " ['37,8' 0 0 1 0 0 1]\n",
      " ['37,9' 0 0 1 1 0 1]\n",
      " ['37,9' 0 0 1 1 0 1]\n",
      " ['37,9' 0 1 0 0 0 0]\n",
      " ['37,9' 0 0 1 1 1 1]\n",
      " ['37,9' 0 0 1 0 0 1]\n",
      " ['38,0' 0 1 1 0 1 0]\n",
      " ['38,0' 0 1 1 0 1 0]\n",
      " ['38,1' 0 1 1 0 1 0]\n",
      " ['38,3' 0 1 1 0 1 0]\n",
      " ['38,5' 0 1 1 0 1 0]\n",
      " ['38,7' 0 1 1 0 1 0]\n",
      " ['38,9' 0 1 1 0 1 0]\n",
      " ['39,0' 0 1 1 0 1 0]\n",
      " ['39,4' 0 1 1 0 1 0]\n",
      " ['39,7' 0 1 1 0 1 0]\n",
      " ['40,0' 1 1 1 1 1 1]\n",
      " ['40,0' 1 1 1 1 1 1]\n",
      " ['40,0' 1 1 1 1 0 1]\n",
      " ['40,0' 0 0 0 0 0 0]\n",
      " ['40,0' 0 0 0 0 0 0]\n",
      " ['40,0' 1 1 0 1 0 0]\n",
      " ['40,0' 1 1 0 1 0 0]\n",
      " ['40,0' 0 1 1 0 1 0]\n",
      " ['40,1' 1 1 1 1 0 1]\n",
      " ['40,2' 1 1 1 1 1 1]\n",
      " ['40,2' 0 0 0 0 0 0]\n",
      " ['40,2' 1 1 0 1 0 0]\n",
      " ['40,3' 0 1 1 0 1 0]\n",
      " ['40,4' 1 1 1 1 1 1]\n",
      " ['40,4' 1 1 1 1 0 1]\n",
      " ['40,4' 1 1 1 1 0 1]\n",
      " ['40,4' 0 0 0 0 0 0]\n",
      " ['40,4' 1 1 0 1 0 0]\n",
      " ['40,5' 1 1 1 1 0 1]\n",
      " ['40,6' 1 1 1 1 1 1]\n",
      " ['40,6' 0 0 0 0 0 0]\n",
      " ['40,6' 1 1 0 1 0 0]\n",
      " ['40,7' 1 1 1 1 1 1]\n",
      " ['40,7' 1 1 1 1 0 1]\n",
      " ['40,7' 0 0 0 0 0 0]\n",
      " ['40,7' 1 1 0 1 0 0]\n",
      " ['40,7' 0 1 1 0 1 0]\n",
      " ['40,8' 0 1 1 0 1 0]\n",
      " ['40,9' 1 1 1 1 0 1]\n",
      " ['40,9' 1 1 1 1 0 1]\n",
      " ['40,9' 0 1 1 0 1 0]\n",
      " ['41,0' 1 1 1 1 1 1]\n",
      " ['41,0' 0 0 0 0 0 0]\n",
      " ['41,0' 1 1 0 1 0 0]\n",
      " ['41,0' 0 1 1 0 1 0]\n",
      " ['41,1' 1 1 1 1 1 1]\n",
      " ['41,1' 1 1 1 1 0 1]\n",
      " ['41,1' 0 0 0 0 0 0]\n",
      " ['41,1' 1 1 0 1 0 0]\n",
      " ['41,1' 0 1 1 0 1 0]\n",
      " ['41,2' 1 1 1 1 1 1]\n",
      " ['41,2' 0 0 0 0 0 0]\n",
      " ['41,2' 1 1 0 1 0 0]\n",
      " ['41,2' 0 1 1 0 1 0]\n",
      " ['41,3' 1 1 1 1 0 1]\n",
      " ['41,4' 0 1 1 0 1 0]\n",
      " ['41,5' 0 0 0 0 0 0]\n",
      " ['41,5' 1 1 0 1 0 0]\n",
      " ['41,5' 0 1 1 0 1 0]\n",
      " ['41,5' 0 1 1 0 1 0]]\n",
      "\n",
      "Y = \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loading of data\n",
    "\n",
    "def load_data(filename, target):\n",
    "    dataset = pd.read_csv(\"dataset/\"+filename, sep=\"\\t\")  # read .csv file into dataset variable\n",
    "\n",
    "    print(dataset,\"\\n\")\n",
    "\n",
    "    x = np.array(dataset.drop([target],1)) # x contains all the features. Does not include target\n",
    "    y = np.array(dataset[target]) # y contains the target class \n",
    "\n",
    "    print(\"\\nX = \\n\",x)\n",
    "    print(\"\\nY = \\n\",y)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    return (dataset,x,y,target)\n",
    "\n",
    "inp = load_data(\"diagnosis-data.csv\",\"decision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 0 1 1 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 0 1]\n",
      " [1 1 1 1 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 1 1 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 0 1]\n",
      " [1 1 1 1 0 1]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 1 1 1 0 1]\n",
      " [0 1 1 0 1 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 0]] \n",
      "\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def add_initial_column(x,val):\n",
    "    m = len(x)\n",
    "\n",
    "    initial_column = np.array([val for i in range(m)])\n",
    "    x = np.column_stack((initial_column, x))   \n",
    "    \n",
    "    return x\n",
    "\"\"\"\n",
    "# x_data = add_initial_column(inp[1],-1)\n",
    "x_data = np.array(inp[1])\n",
    "y_data = np.array([inp[2]])\n",
    "y_data = np.transpose(y_data)\n",
    "x_data = x_data[:,1:]\n",
    "print(x_data,\"\\n\")\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(x):\n",
    "    return sigmoid(x)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    # print(\"Exp: \", np.exp(-x))\n",
    "    x = np.array(x, dtype=int)\n",
    "    return 1/(1 + x)\n",
    "\n",
    "def sign(x):\n",
    "    res = 0 if x <= 0 else 1\n",
    "    # print(res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_deriv(x):\n",
    "    x = np.array(x, dtype=int)\n",
    "    return x * ( 1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_single_hidden():\n",
    "    \n",
    "    def __init__(self, numI, numH, numO, x_data, y_data):\n",
    "        self.numI = numI\n",
    "        self.numH = numH\n",
    "        self.numO = numO\n",
    "        self.x = x_data\n",
    "        self.y = y_data\n",
    "        self.epochs = 5000\n",
    "        self.lr = 0.1\n",
    "        self.tp = 0\n",
    "        self.tn = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.cost_array = []\n",
    "        self.initialize_weights()\n",
    "        self.initialize_bias()\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        self.hiddenW = np.random.uniform(size=(self.numI, self.numH))\n",
    "        self.outputW = np.random.uniform(size=(self.numH, self.numO))\n",
    "\n",
    "    def initialize_bias(self):\n",
    "        self.hiddenB = np.random.uniform(size=(1,self.numH))\n",
    "        self.outputB = np.random.uniform(size=(1,self.numO))\n",
    "        \n",
    "    def forward_propagation(self):\n",
    "        self.hidden_layer_activation = np.dot(self.x, self.hiddenW)\n",
    "        self.hidden_layer_activation += self.hiddenB\n",
    "        self.hidden_layer_output = sigmoid(self.hidden_layer_activation)\n",
    "\n",
    "        self.output_layer_activation = np.dot(self.hidden_layer_output, self.outputW)\n",
    "        self.output_layer_activation += self.outputB\n",
    "        self.y_predict = sigmoid(self.output_layer_activation)\n",
    "        \n",
    "    def backward_propagation(self):\n",
    "        self.error = ((self.y - self.y_predict)) #**2).mean()\n",
    "        self.d_y_predict = self.error * sigmoid_deriv(self.y_predict)\n",
    "\n",
    "        self.error_hidden_layer = self.d_y_predict.dot(self.outputW.T)\n",
    "        self.d_hidden_layer = self.error_hidden_layer * sigmoid_deriv(self.hidden_layer_output)\n",
    "        \n",
    "    def update_weights(self):\n",
    "        #print((self.hidden_layer_output.T.dot(self.d_y_predict))* self.lr)\n",
    "        #print((self.outputW))\n",
    "        #print((self.outputW)+((self.hidden_layer_output.T.dot(self.d_y_predict))* self.lr))\n",
    "        self.outputW = (self.outputW)+((self.hidden_layer_output.T.dot(self.d_y_predict))* self.lr)\n",
    "        #self.outputW += self.hidden_layer_output.T.dot(self.d_y_predict) * self.lr\n",
    "        #print(\"hi\",(self.x.T.dot(self.d_hidden_layer)) * self.lr)\n",
    "        #print(self.hiddenW)\n",
    "        #print(self.hiddenW + (self.x.T.dot(self.d_hidden_layer)) * self.lr )\n",
    "        self.hiddenW = (self.hiddenW + (self.x.T.dot(self.d_hidden_layer)) * self.lr )\n",
    "        \n",
    "    def update_bias(self):\n",
    "        self.outputB = self.outputB + (np.sum(self.d_y_predict, axis=0, keepdims=True) * self.lr)\n",
    "        self.hiddenB = self.hiddenB + (np.sum(self.d_hidden_layer, axis=0, keepdims=True) * self.lr)\n",
    "        \n",
    "    def train(self):\n",
    "        temp_error = 100000\n",
    "        for i in range(self.epochs):\n",
    "            self.forward_propagation()\n",
    "            self.backward_propagation()\n",
    "            self.update_weights()\n",
    "            self.update_bias()\n",
    "            self.cost_array.append(self.error)\n",
    "            \n",
    "            \n",
    "    def print_weights(self):\n",
    "        print(\"HiddenW: \",end=\"\")\n",
    "        print(*self.hiddenW)\n",
    "        print(\"OutputW: \",end=\"\")\n",
    "        print(*self.outputW)\n",
    "        \n",
    "    def print_bias(self):\n",
    "        print(\"HiddenB: \",end=\"\")\n",
    "        print(*self.hiddenB)\n",
    "        print(\"OutputB: \",end=\"\")\n",
    "        print(*self.outputB)\n",
    "        \n",
    "    def print_y_predict(self):\n",
    "        print(\"\\n\\nPredicted Value of Y: \", end=\"\")\n",
    "        print(*self.y_predict)\n",
    "        print(\"Expected Value of Y:  \", end=\"\")\n",
    "        print(*self.y)\n",
    "        \n",
    "        for i in self.y_predict:\n",
    "            for j in self.y:\n",
    "                if i==1 and j==1:\n",
    "                    self.tp += 1\n",
    "                elif i == 0 and j == 0:\n",
    "                    self.tn += 1\n",
    "                elif i == 1 and  j == 0:\n",
    "                    self.fp += 1\n",
    "                else:\n",
    "                    self.fn += 1\n",
    "        \n",
    "        print(\"Accuracy = \",((self.tp+self.tn)/(self.tp+self.tn+self.fp+self.fn))*100,\"%\")\n",
    "        print(\"Recall = \",(self.tp)/(self.tp+self.fn))\n",
    "        print(\"Precision = \",(self.tp)/(self.tp+self.fp))\n",
    "        \n",
    "        \n",
    "    def apply_threshold(self):\n",
    "        for i in range(self.y_predict.size):\n",
    "            if self.y_predict[i][0]  < 0.5:\n",
    "                self.y_predict[i][0] = 0\n",
    "            else:\n",
    "                self.y_predict[i][0] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: \n",
      "HiddenW: [0.77485452 0.48318794 0.25928727 0.75606827 0.19434691 0.15329421\n",
      " 0.09533022] [0.71009305 0.62694465 0.38466284 0.10892284 0.34659509 0.7713332\n",
      " 0.19528608] [0.34327853 0.23023833 0.36228844 0.60824239 0.28400572 0.86432676\n",
      " 0.6521719 ] [0.07504234 0.47541461 0.02053135 0.97259419 0.10324775 0.89916351\n",
      " 0.71544399] [0.03885334 0.52960518 0.70872282 0.56450133 0.14552036 0.94048138\n",
      " 0.22739679] [0.0662932  0.21568566 0.04222909 0.76959101 0.29357105 0.61226887\n",
      " 0.38721252]\n",
      "OutputW: [0.28723909] [0.98611236] [0.54156018] [0.07548183] [0.90794135] [0.34944011] [0.40510753]\n",
      "HiddenB: [0.72550743 0.17390327 0.27728418 0.98313649 0.46126799 0.37607223\n",
      " 0.05851534]\n",
      "OutputB: [0.26076573]\n",
      "\n",
      "Final: \n",
      "HiddenW: [0.7748545225654011 0.48318793918134073 0.2592872741212313\n",
      " 0.7560682657964832 0.19434691403192594 0.15329421338135496\n",
      " 0.09533021558880961] [0.7100930519002607 0.6269446484655398 0.3846628406126398\n",
      " 0.10892284178806733 0.3465950895792812 0.7713332017694066\n",
      " 0.195286083373314] [0.3432785331895425 0.23023832875172412 0.3622884391773388\n",
      " 0.6082423899155512 0.2840057198044983 0.8643267584020199\n",
      " 0.6521719004865474] [0.07504233795288195 0.47541461418688635 0.020531349006032484\n",
      " 0.97259418887576 0.10324774585543528 0.8991635118692092 0.715443987173802] [0.03885334187850631 0.5296051765477607 0.7087228157072423\n",
      " 0.5645013341106111 0.145520364627306 0.9404813775556686\n",
      " 0.22739679275602065] [0.0662932042551293 0.21568566357430985 0.042229085359383745\n",
      " 0.7695910050492164 0.2935710481674296 0.6122688716938098\n",
      " 0.38721251657462696]\n",
      "OutputW: [0.28723909] [0.98611236] [0.54156018] [0.07548183] [0.90794135] [0.34944011] [0.40510753]\n",
      "HiddenB: [0.72550743 0.17390327 0.27728418 0.98313649 0.46126799 0.37607223\n",
      " 0.05851534]\n",
      "OutputB: [0.26076573]\n",
      "\n",
      "\n",
      "Predicted Value of Y: [0.] [1.] [0.] [1.] [0.] [0.] [1.] [0.] [1.] [1.] [1.] [0.] [0.] [1.] [0.] [0.] [1.] [1.] [1.] [0.] [0.] [0.] [0.] [1.] [1.] [1.] [1.] [0.] [0.] [1.] [0.] [0.] [0.] [0.] [0.] [1.] [0.] [0.] [0.] [0.] [0.] [0.] [1.] [0.] [0.] [0.] [0.] [1.] [0.] [0.] [0.] [0.] [0.] [1.] [0.] [0.] [0.] [0.] [1.] [0.] [1.] [1.] [1.] [1.] [1.] [1.] [1.] [1.] [1.] [1.] [1.] [1.] [1.] [0.] [0.] [0.] [0.] [1.] [1.] [1.] [0.] [0.] [1.] [1.] [1.] [1.] [0.] [0.] [1.] [1.] [0.] [0.] [1.] [1.] [0.] [0.] [1.] [1.] [1.] [1.] [1.] [1.] [0.] [0.] [1.] [1.] [1.] [0.] [0.] [1.] [1.] [0.] [0.] [1.] [1.] [1.] [0.] [0.] [1.] [1.]\n",
      "Expected Value of Y:  [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [0] [0] [1] [1] [1] [1] [1] [0] [1] [1] [1] [1] [1] [0] [1] [1] [1] [0] [1] [1] [1] [0] [1] [1] [1] [1] [1] [1] [1] [0] [1] [1] [1] [1] [0] [1] [1] [1] [0] [1] [1] [1] [1] [0] [1] [1] [1]\n",
      "Accuracy =  50.0 %\n",
      "Recall =  0.5\n",
      "Precision =  0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "XOR = MLP_single_hidden(6,7,1,x_data,y_data)\n",
    "\n",
    "print(\"Initial: \")\n",
    "XOR.print_weights()\n",
    "XOR.print_bias()\n",
    "\n",
    "XOR.train()\n",
    "\n",
    "print(\"\\nFinal: \")\n",
    "XOR.print_weights()\n",
    "XOR.print_bias()\n",
    "XOR.apply_threshold()\n",
    "XOR.print_y_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
